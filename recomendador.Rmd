---
title: "Cool Title"
output:
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
---

Standard libraries
```{r}
rm(list = ls())
options(scipen=999) # scientific notation

library(data.table)
library(ggplot2)
library(caret)
library(plotly)
library(dplyr)
library(DT)
library(pander)
library(plotly)
library(xts)

#devtools::install_github("luisalejandrolee/utilucho")
library(utilucho)

source("scripts/data_cleaning_and_preparation.R")

```

# Import

```{r}
folder <- "data/raw/"

files <- c("mes_201706", "mes_201707", "mes_201708", "mes_201709", "mes_201710",
           "mes_201711", "mes_201712", "mes_201801", "mes_201802", "mes_201803",
           "mes_201804", "mes_201805", "mes_201806")

all_months <- import_as_list(folder, files)

```

# Clean data (first stage)
```{r}

cols_to_del <- c("TIPO_ID", "tipo_id2", "_NAME_", "CONSTRUCTOR")

# Make ID as character, remove columns, change PERIODO to date format,
# and format column names
clean_dt_in_list(all_months, cols_to_del)

```

```{r}
all_months[[10]]
```

# Sample data and join all months

```{r}
# Sample by choosing n clients from the last month, and then retrieve those for
# previous months

dts_sampled <- get_samples_dts(all_months, 100000, frac = FALSE) # sample data

dt <- rbindlist(dts_sampled) # merge all SAMPLED months in a single data.table
#dt <- rbindlist(all_months) # merge all NON SAMPLED months in a single data.table

#rm(all_months) # delete non merged datasets
#rm(dts_sampled)
# Check how many clients of the original sample remain month after month

#for(i in 1:length(dts_sampled)){
#  print(nrow(dts_sampled[[i]]))
#}
#dts_sampled[[2]]

dt
```



# Clean data (second stage)
## Check duplicates
```{r}
# check how many duplicates per month
dup <- dt[, .(num_id, duplicated(num_id)), by = periodo][V2 == TRUE]
dup[, .N, by = periodo]
```
## Remove duplicates
```{r}
# remove duplicate clients in the same month
dup <- dt[, duplicated(num_id), by = periodo] # keeps in V1 if duplicated
dt <- dt[dup$V1 == FALSE] # keep non-duplicated
rm(dup) # delete duplicates (not needed anymore)
str(dt)
```

# Feature engineering
Next code works fine. To add:
* change NAs with zero? (must be done in the first data cleaning, inside the function)
* subtract t_cred_l1 - t_cred
* make it binary (1 if >0) and that's the target.

* Repeat the same for all desired products and lags (make a function)
* Also do without the binary addition, and that's the main feature engineering

For data exploration: 
* Count number of clients that **aqcuired** (bought) each product
* Count number of clients that **had** (possesion) each product
* Put all of it in a matrix of counts (with many columns). That's the input for
the Shiny app

```{r}
# required to do proper lag (as calendar time, not reported time)
dt <- complete_id_time(dt, "periodo", "num_id")

#dt[order(num_id, periodo), .N, by = num_id] %>% summary()
#dt[order(num_id, periodo)]
```




## Create lags

```{r}


products <- c("cdt", "t_credito", "ahorros")
lags <- c(1, 2, 5)

dt <- dt[order(num_id, periodo)]

test <- dt[, shift(.SD, lags, give.names = TRUE), by = num_id,
                           .SDcols = products]
test



#dt[order(num_id, periodo)]


test1 <- cbind(dt, test)
test1[order(num_id, periodo)][, .(num_id, periodo, cdt, cdt_lag_1, cdt_lag_2,
                                  cdt_lag_5, t_credito, t_credito_lag_1, t_credito_lag_2,
                                  t_credito_lag_5, ahorros, ahorros_lag_1, ahorros_lag_2,
                                  ahorros_lag_5)]
```


```{r}
dt
```


```{r}

```

```{r}
# replace nas with zeros (create function. Also make some functions to give give median, etc)



# create lag variables for each (create function)
# create adquisition variables: when there's a new product (as a dummy) and when dropping one
# create lags for adquisition variables as well



# Check and analyiza data

## check values for each product: max number of products per client
## decide if making an upper bound
## check some stats (create shiny app!.. for time series)
## check correlations
## do a market basket analysis!

# are there products usually bought together?
# does it usually happen that when buying a credit card, another product is always owned?

```


```{r}

# bind data (now that there are less columns)

# particular divisions (chosen by experimenting memory allowance)
#months_2017 <- rbindlist(all_months[1:7])
#months_2018 <- rbindlist(all_months[8:13])


#dt <- rbindlist(list(months_2017, months_2018))
#rm(months_2017, months_2018) # delete old files

#rm(all_months) # delete long list with all months
```























