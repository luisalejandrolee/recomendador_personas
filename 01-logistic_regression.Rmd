---
title: "Cool Title"
output:
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
---

Standard libraries
```{r}
rm(list = ls())
options(scipen=999) # scientific notation

library(data.table)
library(ggplot2)
library(caret)
library(plotly)
library(dplyr)
library(DT)
library(pander)
library(plotly)
library(xts)
library(reshape2)
library(arules)
library(glmnet)
library(mlbench)




#devtools::install_github("luisalejandrolee/utilucho")
library(utilucho)

#source("scripts/data_cleaning_and_preparation.R")

```

# Import

```{r}
# File names contain the sample size used. Need for the import (must match
# a run of the preparation file to save files with this sample)
#sample_size <- 5000
sample_size <- 100000
lags <- 2

folder <- "data/staging/"
file_dt <- paste0("master_n", sample_size , "_lags", max(lags), ".csv")
dt <- fread(paste0(folder, file_dt))

```
# Remove some variables
Due to collineatiry. Particularly, the "diff", "new" and " loss" which are already captured
by the "lag_1" variables. Careful here, because one must keep some "loss" or "new"
variables intended to be the target
```{r}
# target to keep (so exclude from general removal of variables below)
target_var <- "t_credito_new"

# manual removal. Key here to avoid the lag_1 of the target var (perfect collinearity)
cols_manual <- "t_credito_lag_1"

# remove all variables that by construction will probably have perfecto collinearity
# with other regressors
cols_diff <- grep('_diff', names(dt), value = TRUE)
cols_new <- grep('_new', names(dt), value = TRUE)
cols_loss <- grep('_loss', names(dt), value = TRUE)

# put all groups together, but avoid removing the target_var
cols_remove <- c(cols_diff, cols_new, cols_loss, cols_manual)
cols_remove <- cols_remove[!(cols_remove %in% target_var)]

# finally remove the chosen columns
dt[, (cols_remove) := NULL]

#cols_remove
#names(dt)
```


# Missing values

```{r}
# remove all na's
dt <- na.omit(dt)

```

# Train and test split

```{r}
# columns not to be included in the regression
all_cols <- names(dt)[!(names(dt) %in% c("V1", "periodo", "num_id"))]
# target variable
y_cols <- target_var
dt[, (y_cols) := lapply(.SD, as.factor), .SDcols = y_cols] # convert to factor

# all predictor variables (all except the target)
x_cols <- all_cols[!(all_cols %in% y_cols)]

#length(names(dt))
#length(all_cols)
#length(x_cols)
#length(y_cols)

# months to use as test
test_months <- c("2018-06-30")
# train months are all but the ones chosen for test
months <- unique(dt$periodo) # all months in data
train_months <- months[!(months %in% test_months)] # all months but for test

# notice that splits below are not done randomly. This is due to having time
# series variables. If done randomly, one would have the model observing data of
# future purchases to predict past ones (for example, client A in August for training,
# and same client A in July for testing)

# complete training and test set (including x and y), used for traditional logit regression
train_full <- dt[periodo %in% train_months, .SD, .SDcols = all_cols]
test_full <- dt[periodo %in% test_months, .SD, .SDcols = all_cols]

# separate predictors (x) vs target (y) for lasso (glmnet) regression
train_x <- dt[periodo %in% train_months, .SD, .SDcols = x_cols]
train_y <- dt[periodo %in% train_months, lapply(.SD, as.factor), .SDcols = y_cols]

# test split: x for explanatory, y for target
test_x <- dt[periodo %in% test_months, .SD, .SDcols = x_cols]
test_y <- dt[periodo %in% test_months, lapply(.SD, as.factor), .SDcols = y_cols]

#ncol(train_full)
#train_x
#train_y

#test_x
#test_y
```

```{r}
train_full[t_credito_new == "1", .(t_credito_new)]
```

# Logistic regression

```{r}

fit1_logit <- glm(data = train_full, t_credito_new ~., family = "binomial",
                  control = list(maxit = 50))

summary(fit1_logit)
```


```{r}
#fit1_lasso <- glmnet(as.matrix(train_x), as.matrix(train_y), alpha = 1)


#cv_out <- cv.glmnet(as.matrix(train_x), as.matrix(train_y), alpha=1,
#                   family= "binomial",type.measure = "mse" )
```


```{r}

```


