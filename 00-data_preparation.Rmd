---
title: "Cool Title"
output:
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
---

Standard libraries
```{r}
rm(list = ls())
options(scipen=999) # scientific notation

library(data.table)
library(ggplot2)
library(caret)
library(plotly)
library(dplyr)
library(DT)
library(pander)
library(plotly)
library(xts)
library(reshape2)

#devtools::install_github("luisalejandrolee/utilucho")
library(utilucho)
source("scripts/data_cleaning_and_preparation.R")

```
# Parameters
```{r}
sample_size <- 100000 # number of clients (per month)
lags <- seq(1:2) # choose lags
```


# Import

```{r}
folder <- "data/raw/"

files <- c("mes_201706", "mes_201707", "mes_201708", "mes_201709", "mes_201710",
           "mes_201711", "mes_201712", "mes_201801", "mes_201802", "mes_201803",
           "mes_201804", "mes_201805", "mes_201806")

all_months <- import_as_list(folder, files)

```

# Sample date
```{r}
# Sample by choosing n clients from the last month, and then retrieve those for
# previous months
dts_sampled <- get_samples_dts(all_months, sample_size, frac = FALSE) # sample data
```

# Clean data (first stage)
```{r}

cols_to_del <- c("TIPO_ID", "tipo_id2", "_NAME_", "CONSTRUCTOR")

# Make ID as character, remove columns, change PERIODO to date format,
# and format column names
clean_dt_in_list(dts_sampled, cols_to_del)
convert_to_date_all_list(dts_sampled, "periodo")

```

```{r}
#dts_sampled[1:3]
```

# Join all months

```{r}
# Sample by choosing n clients from the last month, and then retrieve those for
# previous months

#dts_sampled <- get_samples_dts(all_months, 1000, frac = FALSE) # sample data
rm(all_months) # delete non merged datasets

dt <- rbindlist(dts_sampled) # merge all SAMPLED months in a single data.table
#dt <- rbindlist(all_months) # merge all NON SAMPLED months in a single data.table
rm(dts_sampled)

# Check how many clients of the original sample remain month after month
#for(i in 1:length(dts_sampled)){
#  print(nrow(dts_sampled[[i]]))
#}
#dts_sampled[[2]]
```



# Clean data (second stage)
## Check duplicates
```{r}
# check how many duplicates per month
dup <- dt[, .(num_id, duplicated(num_id)), by = periodo][V2 == TRUE]
dup[, .N, by = periodo]
```
## Remove duplicates
```{r}
# remove duplicate clients in the same month
dup <- dt[, duplicated(num_id), by = periodo] # keeps in V1 if duplicated
dt <- dt[dup$V1 == FALSE] # keep non-duplicated
rm(dup) # delete duplicates (not needed anymore)
str(dt)
#dt[, .N, by = periodo]
```

# Feature engineering


```{r}
# required to do proper lag (as calendar time, not reported time)
# fills the data.table with entries for all months and all clients (with NA where
# nothing was reported)
dt <- complete_id_time(dt, "periodo", "num_id")

#dt[order(num_id, periodo), .N, by = num_id] %>% summary()
#dt[order(num_id, periodo)]
```




## Create lags

```{r}


#products <- c("t_credito", "crediservice")
products <- names(dt)[3:length(names(dt))] # all variables (except id and periodo)
#lags <- c(1:(length(unique(dt$periodo))-1)) # all possible lags but last one
lags <- lags # reminder that it is chosen at the beggining

dt <- create_lagged_vars(dt, products, lags)
```
## Create acquisition and loss of products


```{r}
# choose products to create aqcuisition variables
# Here, products should only contain the ORIGINAL ones (not lagged, etc.)
products <- products # reminder that products was chosen before. Change if needed

create_acquisition_and_loss(dt, products)
#dt[, .(t_credito, t_credito_lag_1, t_credito_diff, t_credito_new)][order(-t_credito_new)]
```


# Summarize aqcuisition and loss (counts)
Print as a data.table with rows = one month, columns = aqcuisition of each 
product, 
```{r}

# get columns for acquisition (end with '_new')

cols <- grep('_new', names(dt), value=TRUE)
acquisitions <- dt[, lapply(.SD, sum, na.rm = TRUE), by = periodo, .SDcols = cols]


cols <- grep('_loss', names(dt), value=TRUE)
losses <- dt[, lapply(.SD, sum, na.rm = TRUE), by = periodo, .SDcols = cols]

#names(dt)
```

# Lag again: create acquisition and loss

```{r}
# All this chunk is commented: after some tests with a logistic regression,
# the colinearity of this variables hurts the model, so better not to include them

# Lag variables again, this time the ones indicating new products and lost products
# Those might be related to lag tenency, but are different and might impact modelling

# Not done before to avoid messing the plotting (it plots vars with "_new" and "_loss")
#cols_new <- grep('_new', names(dt), value=TRUE)
#cols_loss <- grep('_loss', names(dt), value = TRUE)
#cols <- c(cols_new, cols_loss)

#dt <- create_lagged_vars(dt, cols, lags)



```
# Save files for modelling and analysis

```{r}

# Save master table (for modelling)
folder <- "data/staging/"
file_master <- paste0("master_n", sample_size , "_lags", max(lags), ".csv")
write.csv(dt, paste0(folder, file_master))

# Save acquisitions (for plotting and analysis)
file_acquisitions <- paste0("acquisitions_n", sample_size , "_lags", max(lags), ".csv")
write.csv(acquisitions, paste0(folder, file_acquisitions))


# Save losses (for plotting and analysis)
file_losses <- paste0("losses_n", sample_size , "_lags", max(lags), ".csv")
write.csv(losses, paste0(folder, file_losses))
```

```{r}



# create lags for adquisition variables as well? Might be captured already by lags

## check values for each product: max number of products per client
## decide if making an upper bound
## check some stats (create shiny app!.. for time series)
## check correlations
## do a market basket analysis!

# are there products usually bought together?
# does it usually happen that when buying a credit card, another product is always owned?

```
























